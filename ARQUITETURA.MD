Este plano detalhado serve como um **Guia T√©cnico e de Arquitetura**, descrevendo a constru√ß√£o da solu√ß√£o "Assistente de Reabastecimento Inteligente" em etapas modulares.

## üìÑ Guia T√©cnico de Constru√ß√£o da Solu√ß√£o (Plan-and-Execute)

A solu√ß√£o ser√° constru√≠da em 4 fases, focando na **simplicidade** e **clareza** das decis√µes, mas garantindo a **robustez** e a **escalabilidade** (caracter√≠sticas exigidas para impressionar o gestor da BEES).

---

## üõ†Ô∏è Fase 1: Infraestrutura de Dados (As Funda√ß√µes)

Esta fase configura todos os recursos de dados que os agentes consumir√£o.

### 1.1. Base de Dados Propriet√°ria (Tool 1 - `Client_Profile_Knowledge`)

* **A√ß√£o:** Conectar ao banco de dados **SQLite** existente `customers.db` (com a tabela `client_profiles`).
* **Por que:** Simula a base de clientes propriet√°ria da BEES. O uso de SQL √© essencial para o padr√£o **Text-to-SQL**.
* **Decis√£o T√©cnica:** A chave para a integra√ß√£o no LangChain √© a classe **`SQLDatabase`** (do SQLAlchemy), que estabelece a conex√£o usando `sqlite:///customers.db` e exp√µe o *schema* da tabela ao LLM.

### 1.2. RAG Index (Web Knowledge Cache - TTL)

* **A√ß√£o:** Inicializar o √≠ndice FAISS (`Web_Knowledge_Cache`) usando **Google Embeddings (`models/embedding-001`)**.
* **Por que:** Implementa√ß√£o da arquitetura de **Cache TTL (Time-to-Live)** para otimizar custos de busca web.
* **Decis√£o T√©cnica:** Os *chunks* armazenados (resumos de sites) devem ter **metadados estruturados**:
    ```json
    {
      "brewery_name": "Nome da Cervejaria",
      "url": "https://example.com",
      "summary": "Resumo conciso do site...",
      "creation_date": "2025-11-15",
      "brewery_type": "micro"
    }
    ```
* **Biblioteca:** Usar **FAISS** como banco vetorial local e **LangChain** para integra√ß√£o com embeddings do Google.

---

## ‚öôÔ∏è Fase 2: Desenvolvimento Modular das Ferramentas (Tools)

Cada Tool √© constru√≠da e testada isoladamente para garantir a robustez (padr√£o **Separation of Concerns**).

### 2.1. Tool 1: `get_client_profile`

* **Objetivo:** Receber `client_id` (ou dados de busca), executar a *query* no `customers.db` e retornar o perfil do cliente como um JSON estruturado.
* **Decis√£o T√©cnica:** Utilizar **Gemini 1.5 Flash** via LangChain com **Function Calling** para Text-to-SQL:
    1.  O **schema completo** da tabela `client_profiles` √© injetado diretamente no **System Prompt** do SQL Runner (sem necessidade de RAG Index adicional).
    2.  O LLM (Gemini) gera a *query* SQL usando o schema fornecido.
    3.  O executor SQL executa a *query* na base `customers.db`.
    4.  A fun√ß√£o deve incluir a l√≥gica de *fallback* (procurar por `postal_code` e/ou `client_name` se o `client_id` for ausente).
    5.  Implementar um **Output Parser** para garantir que o resultado seja sempre um JSON estruturado:
        ```json
        {
          "client_id": "C001",
          "client_name": "Nome",
          "client_location_city_state": "San Diego, CA",
          "postal_code": "92101",
          "top3_brewery_types": ["micro", "brewpub", "regional"],
          "top_5_beers_recently": ["Beer 1", "Beer 2", ...],
          "brewery_history": ["Brewery A", "Brewery B", ...]
        }
        ```
    6.  **Formato de resposta interna:** Retornar JSON com `{"sql_query": "...", "search_method": "client_id|postal_code|client_name|not_found", "result": {...}}`

### 2.2. Tool 2: `search_breweries_by_location_and_type`

* **Objetivo:** Receber `city` e `brewery_type` (do Tool 1) e consultar a **API OpenBreweryDB**.
* **Decis√£o T√©cnica:** **Filtro de Hist√≥rico de Compras.** A fun√ß√£o deve ter l√≥gica interna para receber a lista `brewery_history` (do Tool 1) e **filtrar os resultados da API**, garantindo que apenas cervejarias *novas* (n√£o presentes no hist√≥rico) sejam sugeridas. O resultado final deve conter o `name` e `website_url` da sugest√£o escolhida.
* **Tratamento de Erros Robusto:**
    - Se a API retornar erro: `{"error": "API_ERROR", "message": "descri√ß√£o do erro"}`
    - Se n√£o houver resultados na localiza√ß√£o: `{"error": "NO_BREWERIES_IN_LOCATION"}`
    - Se todos os resultados j√° estiverem no hist√≥rico: `{"error": "NO_NEW_BREWERIES_FOUND"}`
    - Sucesso: `{"suggested_name": "Nome", "website_url": "https://...", "brewery_type": "micro"}`

### 2.3. Tool 3: `get_website_summary`

* **Objetivo:** Receber `url` e retornar o resumo do site, priorizando o cache (RAG Index FAISS).
* **Decis√£o T√©cnica:** Implementa√ß√£o da l√≥gica de **Cache TTL e Fallback**:
    1.  Tentar busca sem√¢ntica no **RAG Index (FAISS)** pelo nome/URL da cervejaria usando **Google Embeddings (`models/embedding-001`)**.
    2.  Se encontrado (Cache Hit): Checar o metadado `creation_date`. Se for mais antigo que 30 dias, marcar como **inv√°lido** (Cache Stale).
    3.  Se Cache Miss ou Inv√°lido: Disparar o **Google Search API** (via LangChain) para a URL.
    4.  Usar **BeautifulSoup** ou similar para extrair o conte√∫do HTML limpo.
    5.  Usar **Gemini 1.5 Flash** para gerar um resumo conciso (m√°ximo 3 frases).
    6.  Se for uma busca nova/atualiza√ß√£o: Criar um novo *chunk* com metadados completos (brewery_name, url, summary, creation_date, brewery_type) e indexar no **RAG Index FAISS**, garantindo que o cache seja "aquecido" para o pr√≥ximo cliente.
    7.  Salvar o √≠ndice FAISS atualizado no disco.

---

## üß† Fase 3: Orquestra√ß√£o (O C√©rebro do Agente)

Esta fase une as ferramentas no Agente LangChain.

### 3.1. Definindo o LLM e o Agente

* **A√ß√£o:** Instanciar o **Gemini 1.5 Flash** via LangChain (`ChatGoogleGenerativeAI`) e o **Agente Executor** (`AgentExecutor`).
* **Decis√£o T√©cnica:** 
    - Usar **Function Calling/Tools** nativos do Gemini para garantir que o LLM chame as fun√ß√µes com *inputs* no formato correto.
    - Configurar o modelo com `temperature=0` para respostas determin√≠sticas.
    - Usar a **API Key do Google AI** (n√£o Vertex AI) para conex√£o direta.

### 3.2. Engenharia de Prompt (System Prompt)

* **A√ß√£o:** Aplicar o **System Prompt** rigoroso que definimos, garantindo o papel, o objetivo e o **Plano de Execu√ß√£o Obrigat√≥rio** de 5 passos.
* **Decis√£o T√©cnica:** O prompt √© o principal guia do agente, for√ßando o fluxo: **Contexto (Tool 1) ‚Üí Busca (Tool 2) ‚Üí Otimiza√ß√£o de Custo (Pergunta Condicional) ‚Üí Detalhe (Tool 3)**.

### 3.3. L√≥gica Condicional (Passo 3 & 4)

* **A√ß√£o:** O c√≥digo Python principal deve gerenciar o fluxo de conversa√ß√£o (chat loop).
* **Decis√£o T√©cnica:** Ap√≥s o **Passo 3** (resposta inicial), o *loop* deve pausar, enviar a pergunta de otimiza√ß√£o de custo ao usu√°rio usando o formato exato: 
    > "Gostaria de ver um resumo detalhado sobre {brewery_name}? (Responda 'sim' ou 'n√£o')"
* **Timeout:** Se n√£o houver resposta em 30 segundos, assumir "n√£o" e prosseguir diretamente para o Passo 5.
* **Controle:** S√≥ chamar a **Tool 3** (`get_website_summary`) se a resposta for "Sim", "sim", "yes" ou varia√ß√µes. Isso √© feito fora da l√≥gica interna do LLM (no c√≥digo do *Agent Handler*), garantindo controle de custos e lat√™ncia.

---

## ÔøΩ Fase 4: Interface de Intera√ß√£o (Chat Conversacional)

Esta fase implementa a interface de usu√°rio para testar e validar o agente em modo conversacional.

### 4.1. Script Main.py (CLI Interativo)

* **Objetivo:** Criar um script Python execut√°vel que permita intera√ß√£o via terminal em modo chat.
* **Funcionalidades:**
    - **Modo Interativo:** Loop conversacional que mant√©m o contexto da sess√£o
    - **Entrada de Client ID:** Permitir que o usu√°rio informe o `client_id` no in√≠cio ou deixe o agente identific√°-lo
    - **Hist√≥rico de Conversa:** Manter mensagens anteriores vis√≠veis para contexto
    - **Comandos Especiais:**
        * `/exit` ou `/quit` - Sair do chat
        * `/clear` - Limpar hist√≥rico da conversa
        * `/log` - Mostrar Chain-of-Thought da √∫ltima execu√ß√£o
        * `/metrics` - Mostrar m√©tricas de performance da sess√£o
    - **Feedback Visual:** Indicadores de status (ü§î Pensando..., ‚úÖ Pronto, ‚ö†Ô∏è Erro)
    - **Tratamento de Timeout:** Interface clara para a pergunta condicional do Passo 3

* **Decis√£o T√©cnica:**
    - Usar biblioteca `rich` para interface colorida e formatada no terminal
    - Implementar classe `ChatSession` para gerenciar estado da conversa
    - Integrar com o `AgentExecutor` do LangChain mantendo contexto entre mensagens

* **Exemplo de Execu√ß√£o:**
```bash
# Modo interativo (usu√°rio informa client_id durante conversa)
python main.py

# Modo direto com client_id
python main.py --client_id C001

# Modo debug (mostra logs detalhados)
python main.py --debug
```

### 4.2. Tratamento de Fluxo Conversacional

* **A√ß√£o:** Implementar l√≥gica para gerenciar o fluxo dos 5 passos no contexto de chat:
    1. **Inicializa√ß√£o:** Apresenta√ß√£o do agente e solicita√ß√£o do client_id (se n√£o fornecido)
    2. **Contexto Autom√°tico:** Assim que o client_id √© identificado, executar Tool 1 automaticamente
    3. **Sugest√£o Proativa:** Executar Tool 2 e apresentar sugest√£o
    4. **Pergunta Condicional:** Pausar e aguardar resposta do usu√°rio com timeout visual
    5. **Continua√ß√£o Natural:** Permitir que o usu√°rio fa√ßa perguntas adicionais ap√≥s conclus√£o

* **Decis√£o T√©cnica:** 
    - Implementar m√°quina de estados para controlar em qual passo o agente est√°
    - Usar `asyncio` para gerenciar timeout da pergunta condicional sem bloquear UI
    - Armazenar contexto da conversa em mem√≥ria durante a sess√£o

---

## üöÄ Fase 5: API REST (FastAPI)

Esta fase disponibiliza o agente como servi√ßo web para integra√ß√£o com outros sistemas.

### 5.1. API Endpoints

* **Objetivo:** Criar API REST completa para consumo do agente por aplica√ß√µes externas.

#### Endpoint 1: POST /chat/message
* **Descri√ß√£o:** Enviar mensagem para o agente e receber resposta
* **Request Body:**
```json
{
  "session_id": "uuid-opcional",
  "client_id": "C001",
  "message": "Sugira uma nova cervejaria local",
  "include_trace": false
}
```
* **Response:**
```json
{
  "session_id": "uuid",
  "response": "Texto da resposta do agente",
  "requires_input": false,
  "suggested_actions": ["confirm", "details"],
  "execution_time_ms": 3421,
  "trace": null
}
```

#### Endpoint 2: POST /chat/session
* **Descri√ß√£o:** Criar nova sess√£o de chat
* **Response:**
```json
{
  "session_id": "uuid",
  "created_at": "2025-11-15T14:30:22Z",
  "status": "active"
}
```

#### Endpoint 3: GET /chat/session/{session_id}
* **Descri√ß√£o:** Obter hist√≥rico e status de uma sess√£o
* **Response:**
```json
{
  "session_id": "uuid",
  "messages": [...],
  "client_id": "C001",
  "status": "active",
  "created_at": "...",
  "last_activity": "..."
}
```

#### Endpoint 4: DELETE /chat/session/{session_id}
* **Descri√ß√£o:** Encerrar e limpar uma sess√£o

#### Endpoint 5: GET /health
* **Descri√ß√£o:** Health check da API
* **Response:**
```json
{
  "status": "healthy",
  "services": {
    "database": "connected",
    "gemini_api": "connected",
    "faiss_index": "loaded"
  }
}
```

#### Endpoint 6: GET /metrics
* **Descri√ß√£o:** M√©tricas agregadas do sistema
* **Response:**
```json
{
  "total_sessions": 42,
  "total_messages": 156,
  "avg_response_time_ms": 3200,
  "cache_hit_rate": 0.78,
  "uptime_seconds": 86400
}
```

### 5.2. Implementa√ß√£o T√©cnica

* **Framework:** FastAPI com Pydantic para valida√ß√£o
* **Autentica√ß√£o:** API Key via header `X-API-Key` (opcional para POC, recomendado para produ√ß√£o)
* **CORS:** Configurado para permitir acesso de frontend
* **Rate Limiting:** Implementar limite de requisi√ß√µes por cliente
* **Session Management:** 
    - Usar Redis (opcional) ou mem√≥ria para sess√µes ativas
    - TTL de 30 minutos para sess√µes inativas
* **Async/Await:** Todos os endpoints ass√≠ncronos para melhor performance
* **Error Handling:** Tratamento consistente de erros com c√≥digos HTTP apropriados
* **Documenta√ß√£o:** OpenAPI/Swagger autom√°tico do FastAPI

### 5.3. Estrutura de Arquivos API

```
api/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ main.py                 # App FastAPI principal
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ request.py         # Pydantic models para requests
‚îÇ   ‚îî‚îÄ‚îÄ response.py        # Pydantic models para responses
‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ chat.py            # Endpoints de chat
‚îÇ   ‚îú‚îÄ‚îÄ health.py          # Health check
‚îÇ   ‚îî‚îÄ‚îÄ metrics.py         # M√©tricas
‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ auth.py            # API Key validation
‚îÇ   ‚îî‚îÄ‚îÄ rate_limit.py      # Rate limiting
‚îî‚îÄ‚îÄ session_manager.py     # Gerenciamento de sess√µes

```

### 5.4. Execu√ß√£o da API

```bash
# Desenvolvimento (com auto-reload)
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000

# Produ√ß√£o
uvicorn api.main:app --host 0.0.0.0 --port 8000 --workers 4

# Docker (opcional)
docker build -t bees-assistant-api .
docker run -p 8000:8000 bees-assistant-api
```

### 5.5. Exemplo de Uso da API

```python
import requests

# Criar sess√£o
session = requests.post("http://localhost:8000/chat/session")
session_id = session.json()["session_id"]

# Enviar mensagem
response = requests.post(
    "http://localhost:8000/chat/message",
    json={
        "session_id": session_id,
        "client_id": "C001",
        "message": "Sugira uma nova cervejaria local"
    },
    headers={"X-API-Key": "your-api-key"}
)

print(response.json()["response"])
```

---

## üìä Fase 6: Observabilidade e Logging

Esta fase garante rastreabilidade completa da execu√ß√£o do agente para debugging e otimiza√ß√£o.

### 4.1. Sistema de Logging

* **A√ß√£o:** Implementar logging estruturado para cada componente:
    - **Tool 1 (SQL Runner):** Logar `timestamp`, `client_id_input`, `sql_query_generated`, `search_method`, `execution_time_ms`, `result_status` (success/error).
    - **Tool 2 (New Opportunities):** Logar `timestamp`, `city`, `brewery_type`, `api_results_count`, `filtered_count`, `selected_brewery`, `execution_time_ms`.
    - **Tool 3 (Web Explorer):** Logar `timestamp`, `url`, `cache_status` (hit/miss/stale), `search_performed` (yes/no), `summary_length`, `execution_time_ms`.
    - **Planner (Orquestrador):** Gerar um **Chain-of-Thought trace completo** com a sequ√™ncia de todas as tool calls, inputs e outputs.

* **Formato:** Salvar logs em arquivo JSON estruturado (`logs/execution_{timestamp}.json`) para an√°lise posterior.

* **Decis√£o T√©cnica:** Usar o m√≥dulo `logging` do Python com formata√ß√£o JSON e rota√ß√£o de arquivos.

### 4.2. M√©tricas de Performance

* **A√ß√£o:** Calcular e reportar ao final de cada execu√ß√£o:
    - Tempo total de execu√ß√£o
    - N√∫mero de tool calls realizadas
    - Cache hit rate (Tool 3)
    - Custo estimado (baseado em tokens consumidos pelo Gemini)

---

## ‚úÖ Fase 7: Teste e Valida√ß√£o

### 7.1. Testes Unit√°rios e de Integra√ß√£o

* **A√ß√£o:** Testar cada Tool em isolamento:
    * **Tool 1:** Testar a recupera√ß√£o do `client_id` (C001), `postal_code` (92101) e o *fallback* de busca. Validar formato JSON de sa√≠da.
    * **Tool 2:** Testar a busca por `San Diego, CA` e `micro`, garantindo que cervejarias listadas no `brewery_history` do cliente C001 **n√£o** sejam sugeridas. Testar todos os cen√°rios de erro (API_ERROR, NO_BREWERIES_IN_LOCATION, NO_NEW_BREWERIES_FOUND).
    * **Tool 3:** Testar o Cache Hit (data recente), Cache Stale (data > 30 dias) e Cache Miss para validar a l√≥gica TTL completa. Verificar persist√™ncia do √≠ndice FAISS.

### 7.2. Teste do Script Main.py (CLI)

* **A√ß√£o:** Validar a interface conversacional:
    - Testar fluxo completo: inicializa√ß√£o ‚Üí consulta ‚Üí sugest√£o ‚Üí resposta condicional ‚Üí conclus√£o
    - Testar comandos especiais (`/exit`, `/clear`, `/log`, `/metrics`)
    - Testar timeout da pergunta condicional (30s)
    - Validar formata√ß√£o visual com `rich`
    - Testar modo debug

### 7.3. Teste da API FastAPI

* **A√ß√£o:** Validar todos os endpoints:
    - Testar cria√ß√£o de sess√£o
    - Testar envio de mensagens com/sem session_id
    - Testar health check
    - Testar m√©tricas agregadas
    - Validar tratamento de erros (client_id inv√°lido, sess√£o inexistente, etc.)
    - Testar rate limiting
    - Validar documenta√ß√£o Swagger em `/docs`

### 7.4. Teste de Ponta a Ponta (E2E)

* **A√ß√£o:** Executar a consulta alvo:
    > "Estou fazendo meu pedido semanal. Baseado no meu perfil de cliente (RAG), me lembre quais s√£o as 3 cervejas que mais pe√ßo. Al√©m disso, sugira uma nova cervejaria local de San Diego (API) que seja do mesmo tipo de estabelecimento que a maioria das minhas fornecedoras ('micro')."
* **Entrega Final (CLI):** Demonstra√ß√£o em v√≠deo/screenshot mostrando:
    1. Execu√ß√£o do `main.py` em modo interativo
    2. Conversa completa com o agente
    3. Visualiza√ß√£o do log com comando `/log`
    4. M√©tricas com comando `/metrics`

* **Entrega Final (API):** 
    1. API rodando em `http://localhost:8000`
    2. Documenta√ß√£o Swagger acess√≠vel em `http://localhost:8000/docs`
    3. Exemplos de requests/responses para cada endpoint
    4. Collection do Postman/Insomnia para testes

---

## üîß Stack Tecnol√≥gico Final

| Componente | Tecnologia | Justificativa |
|:-----------|:-----------|:--------------|
| **LLM Principal** | Gemini 1.5 Flash via LangChain | Baixa lat√™ncia, excelente Function Calling, custo otimizado |
| **Embeddings** | Google `models/embedding-001` | Integra√ß√£o nativa com Google AI, alta qualidade |
| **Banco Vetorial** | FAISS (local) | Gratuito, r√°pido, ideal para datasets pequenos/m√©dios |
| **Banco de Dados** | SQLite (`customers.db`) | J√° existente, zero configura√ß√£o, perfeito para POC |
| **Web Search** | Google Search API via LangChain | Alta qualidade de resultados, integra√ß√£o nativa |
| **Framework** | LangChain | Abstra√ß√µes prontas para Agents, Tools, Chains |
| **Logging** | Python `logging` + JSON | Estruturado, rastre√°vel, analis√°vel |
| **CLI Interface** | Rich + asyncio | Interface moderna, timeout visual, UX profissional |
| **API REST** | FastAPI + Pydantic | Performance ass√≠ncrona, documenta√ß√£o autom√°tica, valida√ß√£o robusta |
| **Session Management** | In-memory (ou Redis) | Stateful, escal√°vel, TTL autom√°tico |

---

Este plano garante que todos os crit√©rios t√©cnicos (LangChain, FAISS, API, M√∫ltiplas Ferramentas, Simplicidade, Clareza) sejam cumpridos, enquanto resolve problemas de engenharia de produ√ß√£o (Escalabilidade, Custo/Lat√™ncia, Observabilidade e **Integra√ß√£o com Sistemas Externos**).